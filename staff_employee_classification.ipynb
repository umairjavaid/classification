{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "staff-employee-classification.ipynb",
      "provenance": [],
      "mount_file_id": "1P_kwCLPRgGwf2qA6eDkQkuhwm0Cp1W3N",
      "authorship_tag": "ABX9TyOhp+hIo31mYcKBXxGFZIDW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umairjavaid/staff-employee-classification/blob/main/staff_employee_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3p9hvjlVli1",
        "outputId": "37a19424-6f0a-46bb-b0a9-6b0aca82ac2b"
      },
      "source": [
        "!git pull https://github.com/umairjavaid/staff-employee-classification"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects:  10% (1/10)\u001b[K\rremote: Counting objects:  20% (2/10)\u001b[K\rremote: Counting objects:  30% (3/10)\u001b[K\rremote: Counting objects:  40% (4/10)\u001b[K\rremote: Counting objects:  50% (5/10)\u001b[K\rremote: Counting objects:  60% (6/10)\u001b[K\rremote: Counting objects:  70% (7/10)\u001b[K\rremote: Counting objects:  80% (8/10)\u001b[K\rremote: Counting objects:  90% (9/10)\u001b[K\rremote: Counting objects: 100% (10/10)\u001b[K\rremote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects:  12% (1/8)\u001b[K\rremote: Compressing objects:  25% (2/8)\u001b[K\rremote: Compressing objects:  37% (3/8)\u001b[K\rremote: Compressing objects:  50% (4/8)\u001b[K\rremote: Compressing objects:  62% (5/8)\u001b[K\rremote: Compressing objects:  75% (6/8)\u001b[K\rremote: Compressing objects:  87% (7/8)\u001b[K\rremote: Compressing objects: 100% (8/8)\u001b[K\rremote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 9 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  11% (1/9)   \rUnpacking objects:  22% (2/9)   \rUnpacking objects:  33% (3/9)   \rUnpacking objects:  44% (4/9)   \rUnpacking objects:  55% (5/9)   \rUnpacking objects:  66% (6/9)   \rUnpacking objects:  77% (7/9)   \rUnpacking objects:  88% (8/9)   \rUnpacking objects: 100% (9/9)   \rUnpacking objects: 100% (9/9), done.\n",
            "From https://github.com/umairjavaid/staff-employee-classification\n",
            " * branch            HEAD       -> FETCH_HEAD\n",
            "Updating c7e4e7c..a382005\n",
            "Fast-forward\n",
            " trainer.py | 692 \u001b[32m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
            " 1 file changed, 692 insertions(+)\n",
            " create mode 100644 trainer.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksssT1XRVlea",
        "outputId": "e3792cc5-cf1f-4b9f-8562-ab834cb6e33b"
      },
      "source": [
        "%cd staff-employee-classification/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/staff-employee-classification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vQXQig1Vlc4",
        "outputId": "f66bd388-9359-4e16-abb4-54b50c5f4ca3"
      },
      "source": [
        "!python staff_employee_other_seperator.py -d /content/drive/MyDrive/omno/mariab_frames_2/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"staff_employee_other_seperator.py\", line 53, in <module>\n",
            "    os.makedirs(new_directory)\n",
            "  File \"/usr/lib/python3.7/os.py\", line 223, in makedirs\n",
            "    mkdir(name, mode)\n",
            "OSError: [Errno 30] Read-only file system: '/content/drive/MyDrive/omno/mariab_frames_2/_content_drive_MyDrive_omno_mariab_frames_2_YOLOv5_format_annotations/'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_jUX7tbVlOY"
      },
      "source": [
        "# KAUSAIN'S MADE \n",
        "#  INFO not updated\n",
        "\n",
        "\"\"\"ABOUT\n",
        "1. To convert VOTT .json annotations into crops of respective dataset images\n",
        "2. To visualize annotations on dataset (VOTT Format .json files)\n",
        "\"\"\"\n",
        "\"\"\"HOW TO USE\n",
        "# python detect_and_remove.py --dataset dataset/\n",
        "# python detect_and_remove.py --dataset dataset/ --remove 1\n",
        "\"\"\"\n",
        "\"\"\"HOW IT WORKS\n",
        "1. Provide a folder with images and VOTT .json annotations and the result will be\n",
        "a folder with {DATASET_ROOT}_crops is created with {DATASET_ROOT} folder, this \n",
        "folder involves all classes/tags of dataset i.e tags of .json files and within \n",
        "each class/tag folder their will be annotated crops\n",
        "2. Viewing annotations on images is also possible  \n",
        "\"\"\"\n",
        "\"\"\"Dependencies\n",
        "- imutils\n",
        "- numpy\n",
        "- opencv\n",
        "\"\"\"\n",
        "\n",
        "# import the necessary packages\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "# construct the argument parser and parse the arguments\n",
        "\n",
        "directory = \"/content/drive/MyDrive/omno/mariab_frames_2\"\n",
        "dict_for_crop_against_img = {}\n",
        "'''dict_for_crop_against_img\n",
        "{img_name_1:[[crops1, class], [crop2, class], [crop3, class] ..], img_name_2: [...], ...}\n",
        "{img_name_1:[[[x,y,w,h], car], [[x,y,w,h], bus], [[x,y,w,h], truck] ..], img_name_2: [...], ...}\n",
        "'''\n",
        "\n",
        "dict_for_img_dimesnsion = {}\n",
        "# image_name =  data['asset']['name'] i.e path\n",
        "# New directory to write crops\n",
        "d_name = args[\"dataset\"].rstrip(\"/\").replace(\"/\", \"_\").replace(\".\",\"\")\n",
        "new_directory = args[\"dataset\"] + f\"{d_name}_YOLOv5_format_annotations/\"\n",
        "\n",
        "if not os.path.exists(new_directory):\n",
        "\tos.makedirs(new_directory)\n",
        "\n",
        "def crop(x0,x1,y1):\n",
        "  return img\n",
        "def save_img(img,path):\n",
        "  return img\n",
        "\n",
        "def get_json_files(directory):\n",
        "\tfiles = glob.glob(f\"{directory}/*.json\")\n",
        "\tfor file in files:\n",
        "\t\t# file_name = file.split(\"/\")[-1]\n",
        "\t\t# print(\"file\", file)\n",
        "\t\twith open(f'./{file}') as f:\n",
        "\t\t\tdata = json.load(f)\n",
        "\t\t\timg_height = data['asset']['size']['height']\n",
        "\t\t\timg_width = data['asset']['size']['width']\n",
        "\t\t\timg_name = f\"{directory}{data['asset']['name']}\"\n",
        "\t\t\tbboxes_for_crop = plot_bboxes(img_name, data)\n",
        "\t\t\tdict_for_crop_against_img[img_name] = bboxes_for_crop \n",
        "\t\t\tdict_for_img_dimesnsion[img_name] = {'h':img_height, 'w':img_width} \n",
        "\treturn dict_for_crop_against_img, dict_for_img_dimesnsion\n",
        "\n",
        "def plot_bboxes(img_path, dict_json_bbox):\n",
        "\tbboxes_for_crop = []\n",
        "\t# all_bboxes = len(dict_json_bbox['regions'])\n",
        "\tfor i, bbox in enumerate(dict_json_bbox['regions']):\n",
        "\t\th = int(bbox['boundingBox']['height'])\n",
        "\t\tx = int(bbox['boundingBox']['left'])\n",
        "\t\ty =\tint(bbox['boundingBox']['top'])\n",
        "\t\tw = int(bbox['boundingBox']['width'])\n",
        "\t\t# bbox_for_crop.append([x,y,w,h])\n",
        "\t\tp1 = (int(x), int(y))\n",
        "\t\tp2 = (int(x+w), int(y+h))\n",
        "\t\t# img = cv2.rectangle(img, p1, p2, (255,255,255), 2)\n",
        "\t\tbboxes_for_crop.append([[x,y,w,h], bbox['tags'][0]])\n",
        "\t\t# print(\"B : \" ,[[x,y,w,h], bbox['tags'][0]])\n",
        "\t\t# import pdb; pdb.set_trace()\n",
        "\treturn bboxes_for_crop\n",
        "\n",
        "def write_txt_file(file_name, content):\n",
        "\twith open(f\"{file_name}.txt\", 'a') as f:\n",
        "\t\t# import pdb; pdb.set_trace()\n",
        "\t\tf.write(content) \n",
        "\n",
        "dict_for_crop_against_img, dict_for_img_dimesnsion = get_json_files(args[\"dataset\"])\n",
        "\n",
        "import pdb; pdb.set_trace()\n",
        "\n",
        "classes_dict = [\"employee\", \"other\", \"person\"]\n",
        "for imageName in dict_for_crop_against_img:\n",
        "\tfor (x, y, w, h), tag in dict_for_crop_against_img[imageName]:\n",
        "\t\timg_h, img_w = dict_for_img_dimesnsion[imageName]['h'], dict_for_img_dimesnsion[imageName]['w']\n",
        "\t\txc_norm = (x + (w/2)) / img_w\n",
        "\t\tyc_norm =  (y + (h/2)) / img_h \n",
        "\t\tw_norm  = w / img_w\n",
        "\t\th_norm  = h / img_h\n",
        "\t\t# NESPAK\n",
        "\t\t# # all other classes\n",
        "\t\t# if \"Truck\" in tag:\n",
        "\t\t# \ttag_number = 12\n",
        "\t\t# else:\n",
        "\t\t# \ttag_number = classes_dict.index(tag)\n",
        "\t\t# wheel only\n",
        "\t\t# tag_number = 0\n",
        "\n",
        "\t\ttag_number = classes_dict.index(tag)\n",
        "\t\tcontent_for_file = str(tag_number) + \" \" + str(xc_norm) + \" \" \\\n",
        "\t\t\t+ str(yc_norm) + \" \" + str(w_norm) + \" \" + str(h_norm) + \"\\n\" \n",
        "\t\tfile_name = imageName.split(\"/\")[-1].replace(\".jpg\", \"\")\n",
        "\t\t#output_file_path = new_directory + file_name\n",
        "\t\t#write_txt_file(output_file_path, content_for_file)\n",
        "print(f\"Done.. Files created in {new_directory}\")\n",
        "# FORMAT for text file (COCO) annotaions for each image \n",
        "# ->class/tag xmin ymin width height \\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1HQpqVNvXFX"
      },
      "source": [
        "from imutils import paths\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "import glob"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "ztgvWJyVjQF6",
        "outputId": "46874198-b1e1-4139-c167-b9bc9795a7a7"
      },
      "source": [
        "#folder dir\n",
        "dir = \"content/drive/MyDrive/omno/mariab_frames_2\"\n",
        "#train dataset dir\n",
        "\n",
        "#returns a dict containing x,y,w,h,img_path\n",
        "def get_json_files(directory):\n",
        "  print(directory)\n",
        "  files = glob.glob(f\"{directory}/*.json\")\n",
        "  for file in files:\n",
        "    print(\"ok\")\n",
        "    with open(f'./{file}') as f:\n",
        "      print(\"pl\")\n",
        "      data = json.load(f)\n",
        "      print(data)\n",
        "      exit()\n",
        "      img_name = data['asset']['name']\n",
        "      img_height = data['regions']['boundingBox']['height']\n",
        "      img_width = data['regions']['boundingBox']['width']\n",
        "      img_left = data['regions']['boundingBox']['left']\n",
        "      img_top = data['regions']['boundingBox']['top']\n",
        "      print(img_name,img_width)\n",
        "      asfasf\n",
        "  \n",
        "\n",
        "get_json_files(dir)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "content/drive/MyDrive/omno/mariab_frames_2\n",
            "ok\n",
            "pl\n",
            "{'asset': {'format': 'jpg', 'id': '30dec0dfc9e8218019c837b97a54aafa', 'name': '0003_231_vid_8_.jpg', 'path': 'file:E:/Omno%20DATA/Frame%20Extract/Maria%20B/mariab_frames_2/0003_231_vid_8_.jpg', 'size': {'width': 1280, 'height': 720}, 'state': 2, 'type': 1}, 'regions': [{'id': 'K9JQBGkgW', 'type': 'RECTANGLE', 'tags': ['other'], 'boundingBox': {'height': 261.05264764083057, 'width': 81.01928560419236, 'left': 1102.1784448212084, 'top': 245.41120027240953}, 'points': [{'x': 1102.1784448212084, 'y': 245.41120027240953}, {'x': 1183.1977304254008, 'y': 245.41120027240953}, {'x': 1183.1977304254008, 'y': 506.46384791324016}, {'x': 1102.1784448212084, 'y': 506.46384791324016}]}, {'id': '4xWSDa607', 'type': 'RECTANGLE', 'tags': ['other'], 'boundingBox': {'height': 103.15791079872533, 'width': 46.29672086929717, 'left': 798.0929215474723, 'top': 116.99013157894737}, 'points': [{'x': 798.0929215474723, 'y': 116.99013157894737}, {'x': 844.3896424167694, 'y': 116.99013157894737}, {'x': 844.3896424167694, 'y': 220.1480423776727}, {'x': 798.0929215474723, 'y': 220.1480423776727}]}, {'id': 'tP3SnxGi6', 'type': 'RECTANGLE', 'tags': ['other'], 'boundingBox': {'height': 98.94735235916941, 'width': 43.14012407521578, 'left': 758.1093942663379, 'top': 115.93751606188323}, 'points': [{'x': 758.1093942663379, 'y': 115.93751606188323}, {'x': 801.2495183415537, 'y': 115.93751606188323}, {'x': 801.2495183415537, 'y': 214.88486842105263}, {'x': 758.1093942663379, 'y': 214.88486842105263}]}, {'id': '6FpvRArxX', 'type': 'RECTANGLE', 'tags': ['other'], 'boundingBox': {'height': 160.00001606188323, 'width': 56.81874229346486, 'left': 599.2273235203453, 'top': 9.62171052631579}, 'points': [{'x': 599.2273235203453, 'y': 9.62171052631579}, {'x': 656.0460658138102, 'y': 9.62171052631579}, {'x': 656.0460658138102, 'y': 169.621726588199}, {'x': 599.2273235203453, 'y': 169.621726588199}]}, {'id': 'pq0RKLO5d', 'type': 'RECTANGLE', 'tags': ['other'], 'boundingBox': {'height': 228.42103656969573, 'width': 104.16769420468557, 'left': 52.08384710234279, 'top': 263.305953176398}, 'points': [{'x': 52.08384710234279, 'y': 263.305953176398}, {'x': 156.25154130702836, 'y': 263.305953176398}, {'x': 156.25154130702836, 'y': 491.72698974609375}, {'x': 52.08384710234279, 'y': 491.72698974609375}]}, {'id': 'YgPzlH_v8', 'type': 'RECTANGLE', 'tags': ['person'], 'boundingBox': {'height': 162.1052470960115, 'width': 59.97533908754624, 'left': 88.91082575524044, 'top': 153.8322529039885}, 'points': [{'x': 88.91082575524044, 'y': 153.8322529039885}, {'x': 148.88616484278668, 'y': 153.8322529039885}, {'x': 148.88616484278668, 'y': 315.9375}, {'x': 88.91082575524044, 'y': 315.9375}]}, {'id': 'lh65ZPY_W', 'type': 'RECTANGLE', 'tags': ['person'], 'boundingBox': {'height': 144.2105423776727, 'width': 55.76651125154131, 'left': 56.29267493834772, 'top': 160.1480423776727}, 'points': [{'x': 56.29267493834772, 'y': 160.1480423776727}, {'x': 112.05918618988903, 'y': 160.1480423776727}, {'x': 112.05918618988903, 'y': 304.3585847553454}, {'x': 56.29267493834772, 'y': 304.3585847553454}]}, {'id': 'su1ymQpKr', 'type': 'RECTANGLE', 'tags': ['person'], 'boundingBox': {'height': 118.94736039011102, 'width': 37.879161528976574, 'left': 185.71314349568433, 'top': 54.884876451994245}, 'points': [{'x': 185.71314349568433, 'y': 54.884876451994245}, {'x': 223.5923050246609, 'y': 54.884876451994245}, {'x': 223.5923050246609, 'y': 173.83223684210526}, {'x': 185.71314349568433, 'y': 173.83223684210526}]}, {'id': 'o-UpyQOVZ', 'type': 'RECTANGLE', 'tags': ['employee'], 'boundingBox': {'height': 93.68420249537418, 'width': 33.67038185881628, 'left': 180.4521327836005, 'top': 26.463823820415296}, 'points': [{'x': 180.4521327836005, 'y': 26.463823820415296}, {'x': 214.12251464241677, 'y': 26.463823820415296}, {'x': 214.12251464241677, 'y': 120.14802631578948}, {'x': 180.4521327836005, 'y': 120.14802631578948}]}], 'version': '2.1.0'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-57f9a9f140bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mget_json_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-57f9a9f140bb>\u001b[0m in \u001b[0;36mget_json_files\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'asset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mimg_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'regions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'boundingBox'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'height'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0mimg_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'regions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'boundingBox'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'width'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mimg_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'regions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'boundingBox'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK21Mii8m3Dy",
        "outputId": "301e87b6-9e73-436a-e99e-1fc2e9193907"
      },
      "source": [
        "import os\n",
        "os.chdir(\"..\")\n",
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bin\t datalab  home\t lib64\topt   run   sys\t\t       tools\n",
            "boot\t dev\t  lib\t media\tproc  sbin  tensorflow-1.15.2  usr\n",
            "content  etc\t  lib32  mnt\troot  srv   tmp\t\t       var\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxFkiWXCnM_k"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}